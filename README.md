# Analysis_of_Titanic_Survivors
- Here we explore and clean the data and analyse which passengers survived the sinking of the titanic. We train out first model and using the results we get we validate them on the test data to make predictions, from the predictions we determine the accuracy percentage.
- To make predictions we use tools from sklearn library like linear regression, logistic regression and cross validation. 
- We go over the entire data, read the csv file then create a numpy array for all the fields we will be using for analysis. Convert all the non numeric fields to numeric so as to avoid sklearn error, we fill al nan with their respective median values. We know that women and children were more likely to survive thus, age and sex are good predictors.
- First we make predictions using Linear Regression then we evaluate the errors by matching the predictors with the actual values. Then we use logistic regression that will take inputs from linear regression and give us a better accuracy.
- We use cross validation to divide the dataa into 3 follds (parts) one for training the algorithm and then test part to predict the algorithm on test set. We will also use Random Forest Classifier that creates a decision tree and creates split points. The advantage here is that split point in each tree is performed on a random subset of the potential columns to split on. 
- We then add features like getting titles from PassengerNames, getting the FamilySize and forming FamilyId (by taking the LastName, FamilySize and concatenating it). We use ensemble feature, it takes linear predictors, a classifier and uses the training set on all predictors. 
-  We use Gradient Boosting while ensembling as it involves training decision trees one after the other and feeds the errors into the succeeding tree. After making the predictions, we validate the algorithm on the test set but before that we make all required changes for the analysis. Finally, we create a submission dataframe containing all the predicted survivors.
